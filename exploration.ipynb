{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1edcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3]\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e296db4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we have to data analysis\n",
    "# data exploration and visualization\n",
    "# here we have to do machine learning\n",
    "# home work form here\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "df = pd.read_csv(\"D:/ashutosh/ML_notes_ashu/Decision_tree/Ashu_dicision_tree/breast_cancer_data.csv\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c7a29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcc1229",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"shape\", df.shape )\n",
    "print(\"-\"*20)\n",
    "print(\"columns\", df.columns )\n",
    "print(\"-\"*20)\n",
    "print(\"info\", df.info() )\n",
    "print(\"-\"*20)   \n",
    "print(\"NULL\", df.isnull().sum() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2773207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we applied df.drop(['id', 'Unnamed: 32'], axis=1, inplace=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312717c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59c6848",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diagnosis'].unique()\n",
    "\n",
    "# here M : Malignant, B : Benign    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79374b16",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbada24",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306358eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output label / Target variable/ Y-Train\n",
    "# we create here pie-plot by using px.pie\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.pie(df, 'diagnosis', \n",
    "             color = 'diagnosis',\n",
    "             color_discrete_sequence=['#FF9999','#66B3FF'],\n",
    "             title=\"Data Distribution\"\n",
    "             )\n",
    "fig.show()\n",
    "\n",
    "# inference\n",
    "# The pie chart shows the distribution of the target variable 'diagnosis' in the dataset.\n",
    "# We can see that the dataset is imbalanced, with a higher proportion of benign cases (B) compared to malignant cases (M).\n",
    "# This imbalance may affect the performance of machine learning models trained on this data.\\\n",
    "# dataset is imbalance[M : B = 63 :37]\n",
    "# We may need to consider techniques such as resampling, class weighting, or using algorithms that are robust to class imbalance.\n",
    "# there are more cases of benign tumors (B) than malignant tumors (M) in the dataset.\n",
    "# for imbalance dataset accuracy may not be a good metric to evaluate model performance.\n",
    "# for example , if 90% of the tumors are benign and 10% are malignant, a model that always predicts benign will have an accuracy of 90%,\n",
    "# but it will not be useful for identifying malignant tumors.\n",
    "# in such cases, we need to use other evaluation metrics such as precision, recall, and F1-score to assess model performance or \"Balanced Accuracy\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca25370",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nbformat >=4.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bc8984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see there is inbalance in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed90473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so visually compare the distribution of each feature\n",
    "# for malignant tumors vs benign tumors\n",
    "# for a given feature, do its values tends to be different for malignant vs benign tumors?\n",
    "\n",
    "for column in df.drop(\"diagnosis\",axis =1).columns[:5]:\n",
    "    # for loop auto iterates through the first five columns in the dataframe\n",
    "    fig = px.box(data_frame = df ,\n",
    "        x = 'diagnosis',\n",
    "        y = column, \n",
    "        color_discrete_sequence= [\"#BA0C0C\",\"#4A13C1\"],\n",
    "        orientation= 'v'\n",
    "    )\n",
    "    fig.show()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad9eb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now again for next five columns \n",
    "for column in df.drop(\"diagnosis\",axis =1).columns[5:10]:\n",
    "    fig = px.scatter(data_frame = df ,\n",
    "        x = column,\n",
    "        color = 'diagnosis',\n",
    "        color_discrete_sequence= [\"#B999FF\",\"#8FFF66\"],\n",
    "        orientation= 'v'\n",
    "    )\n",
    "    fig.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9132b1",
   "metadata": {},
   "source": [
    "###  Creating correlation with the target varialble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725c95ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagnosis is our target variable : M and B : which are catgrical \n",
    "# so we have to encode them into numerical values(0 and 1) M = 1 , B = 0\n",
    "df['diagnosis'] = (df['diagnosis']=='M').astype(int)\n",
    "# this line converts the categorical variable 'diagnosis' into a numerical format\n",
    "corr = df.corr()\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm')   # for correlation always use heatmap\n",
    "plt.show()\n",
    "\n",
    "# correlation always is between -1 and 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8245e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also use \n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91090282",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c4ab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should now choose which features are good enough predirectors to be used to train the model\n",
    "# we will get the absolute correlation values with the target variable  \n",
    "\n",
    "corr_target = abs(corr[\"diagnosis\"])\n",
    "# we will select better correlated features \n",
    "# this is the filtering step\n",
    "# it creates a new list of relevant features    \n",
    "relevant_features = corr_target[corr_target>0.25] # it should be greater than at least 25%\n",
    "# 0.25 is user defined threshold. it is the hyperparameter for feature selection , it is ideal value\n",
    "\n",
    "# now we will collect the names of the relevant features\n",
    "# we will write list comprehension\n",
    "name = [index for index , value in relevant_features.items()]\n",
    "\n",
    "# now we will drop the target variable from the feature set bcause corr of diagnosis will always 1 so no need the target varable\n",
    "name.remove('diagnosis')   \n",
    "\n",
    "pprint.pprint(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259680ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so this above list is the final list of selected features which can be used in model training\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
